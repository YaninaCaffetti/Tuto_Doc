"""
M√≥dulo de Procesamiento de Datos y Generaci√≥n de Arquetipos (Pipeline ETL).

Este script es el coraz√≥n de la ingenier√≠a de datos del proyecto de tesis. Su responsabilidad
es transformar los datos crudos de la encuesta ENDIS en un dataset de entrenamiento
robusto y balanceado para el Tutor Cognitivo basado en Random Forest.

Estrategia Metodol√≥gica:
------------------------
El pipeline implementa una estrategia de "Defensa en Profundidad" para mitigar el sesgo
estad√≠stico inherente en los datos reales (donde los j√≥venes suelen ser etiquetados
autom√°ticamente como 'transici√≥n' independientemente de su formaci√≥n):

1.  **Inyecci√≥n de Datos Sint√©ticos**: Generaci√≥n artificial de casos borde (ej. j√≥venes
    universitarios con discapacidad) que son raros en la muestra real pero cr√≠ticos para la l√≥gica.
2.  **L√≥gica Heur√≠stica Rica ("Fuzzy Rules")**: Asignaci√≥n de arquetipos basada en reglas
    de negocio complejas que consideran educaci√≥n, discapacidad, situaci√≥n laboral y
    rasgos de personalidad simulados (MBTI).
3.  **Candados L√≥gicos ("Hard Constraints")**: Reglas de exclusi√≥n estricta (vetos) que
    impiden, por ejemplo, que un universitario sea clasificado como 'Joven en Transici√≥n'.
4.  **Limpieza Forense ("Relabeling")**: Auditor√≠a post-generaci√≥n para corregir contradicciones
    que hayan sobrevivido a las reglas anteriores.
5.  **Balanceo H√≠brido**: Uso de Upsampling (para minor√≠as) y Downsampling (para mayor√≠as)
    para asegurar que el modelo aprenda todas las clases por igual.

Autora: [Tu Nombre/Rol]
Fecha: 2025
"""

import pandas as pd
import numpy as np
import os
import logging
import yaml
from sklearn.utils import resample

# Importaci√≥n de m√≥dulos del proyecto con manejo de rutas relativas/absolutas
try:
    from src.constants import ALL_ARCHETYPES, TARGET_COLUMN
    from src.profile_inference import (
        run_feature_engineering,
        _simulate_mbti_scores,
        run_fuzzification
    )
except ImportError:
    import sys
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from src.constants import ALL_ARCHETYPES, TARGET_COLUMN
    from src.profile_inference import (
        run_feature_engineering,
        _simulate_mbti_scores,
        run_fuzzification
    )

# Configuraci√≥n del Logging para trazabilidad del proceso
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ==============================================================================
# 1. INYECCI√ìN DE DATOS SINT√âTICOS
# ==============================================================================
def _inject_synthetic_data() -> pd.DataFrame:
    """
    Genera un conjunto de datos sint√©ticos para reforzar patrones estad√≠sticamente d√©biles.

    El prop√≥sito es combatir la "inercia estad√≠stica" de la base de datos real (ENDIS),
    donde ciertas combinaciones de atributos (ej. Joven + T√≠tulo Universitario + Discapacidad)
    son casi inexistentes, llevando al modelo a ignorarlas.

    Returns:
        pd.DataFrame: DataFrame conteniendo las filas sint√©ticas generadas.
    """
    logging.info("üíâ Inyectando datos sint√©ticos para romper la inercia estad√≠stica...")
    synthetic_rows = []
    
    # CASO A: COMUNICADOR DESAFIADO
    # Perfil: Joven, Universitario, con dificultad de Habla o Auditiva.
    # Objetivo: Ense√±ar al modelo que 'Joven' + 'T√≠tulo' NO es igual a 'Transici√≥n'.
    for i in range(500):
        row = {
            'ID': f'SYN_COM_DES_{i}',
            'dificultad_total': 1, 
            'tipo_dificultad': np.random.choice([6, 3]), # 6: Habla, 3: Auditiva
            'dificultades': 1,
            'MNEA': 5, # Universitario Completo (Variable Cr√≠tica)
            'edad_agrupada': np.random.choice([2, 3]), # Joven (15-29) y Adulto Joven
            'Estado_ocup': 2, # Desocupado
            'cat_ocup': 9, 'certificado': 1, 'PC08': 9, 'pc03': 1, 'tipo_hogar': 2
        }
        synthetic_rows.append(row)

    # CASO B: POTENCIAL LATENTE CALIFICADO
    # Perfil: Universitario en inactividad laboral.
    # Objetivo: Diferenciarlo del Comunicador por su 'Estado_ocup' (Inactivo vs Desocupado).
    for i in range(200):
        row = {
            'ID': f'SYN_POT_LAT_{i}',
            'dificultad_total': 1, 'tipo_dificultad': 1, # Motora
            'MNEA': 5, # Universitario
            'edad_agrupada': 3,
            'Estado_ocup': 3, # Inactivo (Variable Cr√≠tica)
            'cat_ocup': 9, 'certificado': 1, 'PC08': 9, 'pc03': 1, 'tipo_hogar': 2
        }
        synthetic_rows.append(row)

    return pd.DataFrame(synthetic_rows)

# ==============================================================================
# 2. INGENIER√çA DE ARQUETIPOS (REGLAS + CANDADOS)
# ==============================================================================
def _calculate_archetype_membership(df: pd.DataFrame) -> pd.DataFrame:
    """
    Calcula el grado de pertenencia de cada individuo a los 6 arquetipos definidos.

    Utiliza una combinaci√≥n de l√≥gica difusa (probabilidades basadas en rasgos) y 
    candados l√≥gicos (reglas de exclusi√≥n estrictas) para asegurar la coherencia.

    Args:
        df (pd.DataFrame): DataFrame con features enriquecidos y scores MBTI simulados.

    Returns:
        pd.DataFrame: DataFrame original con columnas nuevas 'Pertenencia_{Arquetipo}'.
    """
    df_out = df.copy()

    # --- REGLA 1: COMUNICADOR DESAFIADO ---
    def _rule_comunicador(r):
        """Identifica profesionales con barreras espec√≠ficas de comunicaci√≥n."""
        # CANDADO: Solo Capital Humano Alto (Educaci√≥n Superior)
        if r.get('CAPITAL_HUMANO') != '3_Alto': return 0.0
        
        pdif = r.get('Perfil_Dificultad_Agrupado')
        slab = r.get('Espectro_Inclusion_Laboral')
        ei = r.get('MBTI_EI_score_sim', 0.5) # Introversi√≥n/Extroversi√≥n
        
        # Filtro: Debe estar buscando trabajo o en empleo precario
        if slab not in ['2_Busqueda_Sin_Exito', '3_Inclusion_Precaria_Aprox']: return 0.0

        es_comunicacion = pdif in ['1F_Habla_Comunicacion_Unica', '1C_Auditiva_Unica']
        
        prob = 0.0
        if es_comunicacion: 
            prob = 0.95 
        elif pdif == '3_Tres_o_Mas_Dificultades': 
            prob = 0.4 # Posible, pero menos claro
            
        if prob == 0.0: return 0.0
        
        # Matiz MBTI: La introversi√≥n (EI bajo) puede acentuar la percepci√≥n de barrera
        factor = 1.0 + (0.1 * (1 - ei)) 
        return round(min(prob * factor, 1.0), 2)

    # --- REGLA 2: NAVEGANTE INFORMAL ---
    def _rule_navegante(r):
        """Identifica trabajadores informales con alta adaptabilidad."""
        # CANDADO: Generalmente Capital Bajo (No universitarios)
        if r.get('CAPITAL_HUMANO') == '3_Alto': return 0.0
        
        slab = r.get('Espectro_Inclusion_Laboral')
        jp = r.get('MBTI_JP_score_sim', 0.5) # Judging/Perceiving
        
        if slab not in ['3_Inclusion_Precaria_Aprox', '2_Busqueda_Sin_Exito']: return 0.0
        
        prob = 0.85
        # Matiz MBTI: Alta 'Percepci√≥n' (flexibilidad/improvisaci√≥n) favorece este perfil
        factor = 1.0 + (0.1 * jp)
        return round(min(prob * factor, 1.0), 2)

    # --- REGLA 3: PROFESIONAL SUBUTILIZADO ---
    def _rule_profesional(r):
        """Identifica capital humano alto en roles que no aprovechan sus competencias."""
        # CANDADO: Requiere Capital Medio o Alto
        if r.get('CAPITAL_HUMANO') == '1_Bajo': return 0.0
        
        pdif = r.get('Perfil_Dificultad_Agrupado')
        slab = r.get('Espectro_Inclusion_Laboral')
        
        if slab not in ['2_Busqueda_Sin_Exito', '3_Inclusion_Precaria_Aprox']: return 0.0
        
        # Dificultades "manejables" con ajustes razonables est√°ndar
        es_dificultad_menor = pdif in ['0_Sin_Dificultad_Registrada', '4_Solo_Certificado', '1A_Motora_Unica', '1B_Visual_Unica']
        
        if es_dificultad_menor: return 0.90
        return 0.0

    # --- REGLA 4: POTENCIAL LATENTE ---
    def _rule_potencial(r):
        """Identifica personas inactivas laboralmente por desaliento o barreras sist√©micas."""
        slab = r.get('Espectro_Inclusion_Laboral')
        pdif = r.get('Perfil_Dificultad_Agrupado')
        
        # CANDADO: Debe estar en Inactividad (Exclusi√≥n del mercado)
        if slab != '1_Exclusion_del_Mercado': return 0.0
        
        prob = 0.6
        # Mayor probabilidad si hay dificultades severas o desaliento profesional
        if pdif in ['1E_Autocuidado_Unica', '3_Tres_o_Mas_Dificultades']: prob = 0.95
        elif r.get('CAPITAL_HUMANO') == '3_Alto': prob = 0.85 
        
        return prob

    # --- REGLA 5: CANDIDATO CON NECESIDADES SIGNIFICATIVAS ---
    def _rule_necesidades(r):
        """Identifica perfiles que requieren apoyos intensivos y personalizados."""
        pdif = r.get('Perfil_Dificultad_Agrupado')
        
        # CANDADO: Si es Universitario, se requiere dificultad extrema para caer aqu√≠
        if r.get('CAPITAL_HUMANO') == '3_Alto' and pdif not in ['3_Tres_o_Mas_Dificultades', '1E_Autocuidado_Unica']:
             return 0.0

        if pdif in ['3_Tres_o_Mas_Dificultades', '1E_Autocuidado_Unica']: return 0.95
        return 0.0

    # --- REGLA 6: JOVEN EN TRANSICI√ìN (LA CR√çTICA) ---
    def _rule_joven(r):
        """
        Identifica j√≥venes en etapa formativa o de primera inserci√≥n.
        Esta regla contiene el FIX PRINCIPAL para el sesgo de edad.
        """
        grupo_edad = r.get('GRUPO_ETARIO_INDEC')
        capital = r.get('CAPITAL_HUMANO')
        asiste_educacion = r.get('PC08')
        
        # CANDADO 1: EDAD (Solo j√≥venes adultos tempranos)
        if grupo_edad != '1_Joven_Adulto_Temprano (14-39)': return 0.0
        
        # ---------------------------------------------------------
        # CANDADO 2 (CR√çTICO): EXCLUSI√ìN POR NIVEL EDUCATIVO
        # Si tiene t√≠tulo universitario (Capital Alto), NO es transici√≥n.
        # Debe ser clasificado como Profesional o Comunicador.
        # ---------------------------------------------------------
        if capital == '3_Alto': return 0.0
        
        prob = 0.0
        if asiste_educacion == 1: prob = 0.95 # Asiste actualmente
        else: prob = 0.75 # Joven sin capital alto y sin asistir
        
        return prob

    # Mapeo de reglas y ejecuci√≥n
    reglas = {
        'Com_Desafiado': _rule_comunicador,
        'Nav_Informal': _rule_navegante,
        'Prof_Subutil': _rule_profesional,
        'Potencial_Latente': _rule_potencial,
        'Cand_Nec_Sig': _rule_necesidades,
        'Joven_Transicion': _rule_joven,
    }

    for arch, func in reglas.items():
        try:
            df_out[f'Pertenencia_{arch}'] = df_out.apply(func, axis=1)
        except Exception as e:
            logging.error(f"Error aplicando regla para {arch}: {e}")
            df_out[f'Pertenencia_{arch}'] = 0.0

    return df_out

# ==============================================================================
# 3. LIMPIEZA DE ETIQUETAS (RELABELING POST-GENERACI√ìN)
# ==============================================================================
def _fix_inconsistent_labels(df: pd.DataFrame) -> pd.DataFrame:
    """
    Realiza una auditor√≠a final sobre las etiquetas generadas para corregir contradicciones l√≥gicas.

    Incluso con reglas estrictas, datos sucios o combinaciones extra√±as en la base original
    pueden generar etiquetas inconsistentes. Esta funci√≥n act√∫a como un "filtro de calidad".

    Correcciones espec√≠ficas implementadas:
    - Reclasificaci√≥n de 'Joven_Transicion' si posee T√≠tulo Universitario.

    Args:
        df (pd.DataFrame): DataFrame con la columna TARGET_COLUMN asignada.

    Returns:
        pd.DataFrame: DataFrame con etiquetas corregidas.
    """
    df_clean = df.copy()
    
    # DETECTAR: Etiquetado como 'Joven_Transicion' PERO con Capital Humano Alto (> 0.5)
    mask_error = (df_clean[TARGET_COLUMN] == 'Joven_Transicion') & (df_clean['CH_Alto_memb'] > 0.5)
    
    count_errors = mask_error.sum()
    if count_errors > 0:
        logging.warning(f"üîÑ RELABELING: Corrigiendo {count_errors} inconsistencias (Joven Transici√≥n con T√≠tulo Univ).")
        
        # Sub-regla A: Si tiene dificultad de Habla o Sensorial -> Com_Desafiado
        mask_com = mask_error & ((df_clean['PD_ComCog_memb'] > 0.5) | (df_clean['PD_Sensorial_memb'] > 0.5))
        df_clean.loc[mask_com, TARGET_COLUMN] = 'Com_Desafiado'
        
        # Sub-regla B: El resto -> Prof_Subutil
        mask_prof = mask_error & (~mask_com)
        df_clean.loc[mask_prof, TARGET_COLUMN] = 'Prof_Subutil'
        
        logging.info(f"   ‚Ä∫ Reasignados a Com_Desafiado: {mask_com.sum()}")
        logging.info(f"   ‚Ä∫ Reasignados a Prof_Subutil: {mask_prof.sum()}")
    
    return df_clean

# ==============================================================================
# MAIN PIPELINE
# ==============================================================================
def run_archetype_engineering(df: pd.DataFrame) -> pd.DataFrame:
    """
    Orquestador principal de la generaci√≥n de arquetipos.
    
    Pasos:
    1. Simulaci√≥n de rasgos de personalidad (MBTI).
    2. C√°lculo de membres√≠a a arquetipos usando reglas y candados.
    
    Args:
        df (pd.DataFrame): DataFrame con features procesados.
        
    Returns:
        pd.DataFrame: DataFrame enriquecido con columnas de pertenencia a arquetipos.
    """
    # 1. Simular MBTI (aporta "textura" y realismo psicol√≥gico a los datos)
    df_mbti = _simulate_mbti_scores(df)
    
    # 2. Calcular Pertenencias (N√∫cleo de la l√≥gica de negocio)
    df_archetyped = _calculate_archetype_membership(df_mbti)
    
    return df_archetyped

if __name__ == '__main__':
    # --- Bloque Principal de Ejecuci√≥n ---
    
    # 1. Carga de Configuraci√≥n
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        logging.error(f"Error cargando config.yaml: {e}")
        config = {'data_paths': {'raw_data': 'data/ENDIS_Completo.csv'}}

    RAW_DATA_PATH = config.get('data_paths', {}).get('raw_data', 'data/ENDIS_Completo.csv')
    
    logging.info("--- ‚öôÔ∏è Iniciando Pipeline de Procesamiento de Datos ---")

    # 2. Carga de Datos Crudos
    if os.path.exists(RAW_DATA_PATH):
        try:
            df_raw = pd.read_csv(RAW_DATA_PATH, delimiter=';', encoding='latin1', low_memory=False, on_bad_lines='warn')
            logging.info(f"Datos crudos cargados: {len(df_raw)} filas.")
        except Exception as e:
            logging.error(f"Error leyendo CSV: {e}"); exit()
    else:
        logging.error(f"No se encuentra el archivo: {RAW_DATA_PATH}"); exit()

    # 3. Inyecci√≥n de Datos Sint√©ticos (Capa 1 de Defensa)
    df_synthetic = _inject_synthetic_data()
    df_combined = pd.concat([df_raw, df_synthetic], ignore_index=True)
    logging.info(f"Dataset combinado: {len(df_combined)} filas (Originales + Sint√©ticos).")

    # 4. Feature Engineering y Fuzzificaci√≥n
    df_featured = run_feature_engineering(df_combined)
    df_archetyped = run_archetype_engineering(df_featured)
    df_fuzzified = run_fuzzification(df_archetyped)

    # 5. Asignaci√≥n del Target Inicial (Winner takes all)
    archetype_cols = [f'Pertenencia_{name}' for name in ALL_ARCHETYPES]
    
    # Filtro de calidad: eliminar filas donde ninguna regla aplic√≥ significativamente
    df_fuzzified['MAX_SCORE'] = df_fuzzified[archetype_cols].max(axis=1)
    df_clean = df_fuzzified[df_fuzzified['MAX_SCORE'] > 0.1].copy()
    
    # Asignar etiqueta ganadora
    df_clean[TARGET_COLUMN] = df_clean[archetype_cols].idxmax(axis=1).str.replace('Pertenencia_', '')

    # 6. Limpieza de Etiquetas / Relabeling (Capa 3 de Defensa)
    df_corrected = _fix_inconsistent_labels(df_clean)

    # 7. Balanceo H√≠brido (Capa 4 de Defensa)
    logging.info("--- ‚öñÔ∏è Ejecutando Balanceo H√≠brido (Tijera) ---")
    
    MIN_SAMPLES = 1000  # Piso para minor√≠as (Upsampling)
    MAX_SAMPLES = 3000  # Techo para mayor√≠as (Downsampling)
    
    dfs_balanced = []
    
    counts_before = df_corrected[TARGET_COLUMN].value_counts()
    logging.info(f"Distribuci√≥n antes del balanceo:\n{counts_before}")

    for archetype in ALL_ARCHETYPES:
        df_arch = df_corrected[df_corrected[TARGET_COLUMN] == archetype]
        count = len(df_arch)
        
        if count == 0:
            logging.warning(f"‚ö†Ô∏è Arquetipo vac√≠o: {archetype}")
            continue
            
        if count < MIN_SAMPLES:
            # Upsample: Duplicar muestras para alcanzar el m√≠nimo
            df_res = resample(df_arch, replace=True, n_samples=MIN_SAMPLES, random_state=42)
            logging.info(f"  ‚¨ÜÔ∏è Upsample {archetype}: {count} -> {MIN_SAMPLES}")
        elif count > MAX_SAMPLES:
            # Downsample: Reducir muestras para no exceder el m√°ximo
            df_res = resample(df_arch, replace=False, n_samples=MAX_SAMPLES, random_state=42)
            logging.info(f"  ‚¨áÔ∏è Downsample {archetype}: {count} -> {MAX_SAMPLES}")
        else:
            # Mantener: Cantidad ideal
            df_res = df_arch
            
        dfs_balanced.append(df_res)

    df_final = pd.concat(dfs_balanced).sample(frac=1, random_state=42).reset_index(drop=True)
    
    # 8. Guardado de Resultados
    # Seleccionar solo columnas num√©ricas (fuzzy features) + Target para el entrenamiento
    feature_cols = [col for col in df_final.columns if '_memb' in col]
    df_training = df_final[feature_cols + [TARGET_COLUMN]].fillna(0.0)
    
    out_dir = os.path.join(os.getcwd(), 'data')
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, 'cognitive_profiles.csv')
    
    df_training.to_csv(out_path, index=False)
    logging.info(f"‚úÖ Dataset de entrenamiento guardado en: {out_path}")
    logging.info(f"Distribuci√≥n Final:\n{df_final[TARGET_COLUMN].value_counts()}")
    
    # Generar Demo Set (peque√±a muestra para pruebas r√°pidas de inferencia)
    demo_samples = []
    for arch in ALL_ARCHETYPES:
        subset = df_final[df_final[TARGET_COLUMN] == arch]
        if not subset.empty:
            demo_samples.append(subset.iloc[0:2]) # Tomar 2 ejemplos de cada clase
    if demo_samples:
        pd.concat(demo_samples).to_csv(os.path.join(out_dir, 'demo_profiles.csv'), index=False)

    logging.info("üèÅ Pipeline finalizado con √©xito.")
