# train.py 

import pandas as pd
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import traceback
import yaml
import os
import joblib

# Importar  m√≥dulos locales
from src.data_processing import run_feature_engineering, run_archetype_engineering, run_fuzzification
from src.emotion_classifier import train_and_evaluate_emotion_classifier
from imblearn.over_sampling import SMOTE

def train_and_evaluate_all(config: dict):
    """
    Orquesta el pipeline completo de entrenamiento, evaluaci√≥n y guardado de modelos.

    Este script ejecuta dos pipelines principales en secuencia:
    1.  **Clasificador de Emociones:** Entrena y eval√∫a un modelo BERT fine-tuned
        para la clasificaci√≥n de emociones a partir de texto.
    2.  **Tutor Cognitivo:** Procesa los datos de la encuesta ENDIS, entrena un modelo
        RandomForest para clasificar perfiles de usuario en arquetipos y guarda
        los modelos y perfiles de demostraci√≥n necesarios para la aplicaci√≥n.

    Args:
        config (dict): El diccionario de configuraci√≥n cargado desde config.yaml.
    """
    print("\n--- üöÄ INICIANDO PIPELINE DE ENTRENAMIENTO Y EVALUACI√ìN ---")

    # --- Parte I: Entrenamiento y Guardado del Clasificador de Emociones ---
    print(f"\n--- [PARTE I] Entrenando y Evaluando el Clasificador de Emociones... ---")
    try:
        train_and_evaluate_emotion_classifier(config)
        print("--- ‚úÖ Parte I completada: Clasificador de Emociones entrenado y guardado. ---")
    except Exception as e:
        print(f"‚ùå ERROR CR√çTICO EN LA PARTE I (Clasificador de Emociones): {e}")
        traceback.print_exc()
        return # Detener la ejecuci√≥n si esta parte crucial falla

    # --- Parte II: Entrenamiento y Benchmarking del Tutor Cognitivo ---
    print("\n--- [PARTE II] Entrenando y Evaluando el Tutor Cognitivo... ---")
    
    try:
        # --- A. Carga y Procesamiento de Datos ---
        print("  ‚Ä∫ Cargando el dataset cognitivo...")
        df_raw = pd.read_csv(config['data_paths']['endis_raw'], delimiter=';', low_memory=False, index_col='ID')
        print("  ‚Ä∫ Dataset cargado exitosamente.")
        
        df_featured = run_feature_engineering(df_raw)
        df_archetyped = run_archetype_engineering(df_featured)
        df_fuzzified = run_fuzzification(df_featured)
        
        # --- B. Creaci√≥n y Guardado de Perfiles para la Demostraci√≥n ---
        demo_ids = config['data_paths'].get('demo_user_ids', []) # Usar IDs del config o una lista vac√≠a
        valid_demo_ids = [uid for uid in demo_ids if uid in df_fuzzified.index]
        
        if valid_demo_ids:
            demo_profiles_df = df_fuzzified.loc[valid_demo_ids].copy()
            # Forzar escenario de CUD si el ID 14 est√° en la lista para asegurar la demo
            if 14 in demo_profiles_df.index:
                demo_profiles_df.loc[14, 'TIENE_CUD'] = 'Si_Tiene_CUD'
                print("  ‚Ä∫ Perfil de demo forzado: ID 14 tiene CUD.")
            
            os.makedirs(os.path.dirname(config['data_paths']['demo_profiles']), exist_ok=True)
            demo_profiles_df.to_csv(config['data_paths']['demo_profiles'], index=True)
            print(f"  ‚Ä∫ Perfiles de demostraci√≥n guardados para los IDs: {valid_demo_ids}")
        else:
            print("  ‚Ä∫ Advertencia: Ninguno de los IDs de demo especificados en config.yaml se encontr√≥ en el dataset.")

        # --- C. Preparaci√≥n Final de Datos para Entrenamiento ---
        pertenencia_cols_map = {col: col.replace('Pertenencia_', '') for col in df_fuzzified.columns if 'Pertenencia_' in col}
        df_fuzzified.rename(columns=pertenencia_cols_map, inplace=True)
        
        from src.cognitive_tutor import EXPERT_MAP
        columnas_arquetipos = [col for col in df_fuzzified.columns if col in EXPERT_MAP.keys()]
        
        def determinar_arquetipo_predominante(row: pd.Series) -> str:
            """
            Funci√≥n robusta para asignar una etiqueta de clase final.

            Maneja correctamente los casos donde no hay puntajes de pertenencia (NaNs)
            para evitar el error 'argmax of an empty sequence'.
            """
            pertenencias = row[columnas_arquetipos].dropna() # Clave: .dropna()
            
            if pertenencias.empty or pertenencias.max() < config['constants']['umbrales']['arquetipo']:
                return 'Arquetipo_No_Predominante'
            
            return pertenencias.idxmax()
        
        df_fuzzified['Arquetipo_Predominante'] = df_fuzzified.apply(determinar_arquetipo_predominante, axis=1)
        
        # --- D. Divisi√≥n y Balanceo de Datos (SMOTE) ---
        feature_columns = [col for col in df_fuzzified.columns if '_memb' in col]
        df_entrenamiento = df_fuzzified[df_fuzzified['Arquetipo_Predominante'] != 'Arquetipo_No_Predominante'].copy()

        print(f"  ‚Ä∫ {len(df_entrenamiento)} perfiles superaron el umbral de arquetipo y se usar√°n para el entrenamiento.")

        if len(df_entrenamiento) > 10:
            X_train, X_test, y_train, y_test = train_test_split(
                df_entrenamiento[feature_columns], 
                df_entrenamiento['Arquetipo_Predominante'], 
                test_size=config['model_params']['cognitive_tutor']['test_size'], 
                random_state=config['model_params']['cognitive_tutor']['random_state'], 
                stratify=df_entrenamiento['Arquetipo_Predominante']
            )
            
            print("\n--- Aplicando SMOTE para balancear el conjunto de entrenamiento... ---")
            smote = SMOTE(random_state=config['model_params']['cognitive_tutor']['random_state'])
            X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)
            
            # --- E. Entrenamiento y Guardado del Modelo Cognitivo ---
            cfg_cog = config['model_params']['cognitive_tutor']
            
            print("\n--- Entrenando el modelo cognitivo final (RandomForest)... ---")
            model = RandomForestClassifier(
                n_estimators=cfg_cog['n_estimators'], 
                max_depth=cfg_cog['max_depth'], 
                random_state=cfg_cog['random_state']
            ).fit(X_train_sm, y_train_sm)
            
            cognitive_model_path = config['model_paths']['cognitive_tutor']
            os.makedirs(os.path.dirname(cognitive_model_path), exist_ok=True)
            joblib.dump(model, cognitive_model_path)
            print(f"  ‚Ä∫ Modelo cognitivo guardado exitosamente en: {cognitive_model_path}")
            print("--- ‚úÖ Parte II completada. ---")
            
        else:
            raise ValueError("No hay suficientes datos para entrenar el tutor cognitivo despu√©s del filtrado.")

    except Exception as e:
        print(f"‚ùå ERROR CR√çTICO EN LA PARTE II (Tutor Cognitivo): {e}")
        traceback.print_exc()

if __name__ == '__main__':
    """
    Punto de entrada del script.

    Carga la configuraci√≥n desde 'config.yaml' y ejecuta el pipeline principal
    de entrenamiento y evaluaci√≥n.
    """
    try:
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        train_and_evaluate_all(config)
        print("\n‚úÖ --- Proceso de entrenamiento, evaluaci√≥n y guardado finalizado. ---")
    except FileNotFoundError:
        print("‚ùå Error: No se encontr√≥ el archivo 'config.yaml'. Aseg√∫rate de que exista en el directorio ra√≠z.")
    except Exception as e:
        print(f"‚ùå Un error inesperado ocurri√≥ durante la ejecuci√≥n: {e}")
        traceback.print_exc()
